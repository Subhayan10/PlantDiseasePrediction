{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bPtJVGxrosw",
        "outputId": "bd7adbeb-bded-4466-ef39-15bd359ef969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 2023 images belonging to 5 classes.\n",
            "Found 503 images belonging to 5 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1323s\u001b[0m 21s/step - accuracy: 0.2163 - loss: 1.9556 - val_accuracy: 0.2505 - val_loss: 1.6976\n",
            "Epoch 2/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - accuracy: 0.3279 - loss: 1.6508 - val_accuracy: 0.3121 - val_loss: 1.5744\n",
            "Epoch 3/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 2s/step - accuracy: 0.3798 - loss: 1.5095 - val_accuracy: 0.4115 - val_loss: 1.4268\n",
            "Epoch 4/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - accuracy: 0.4648 - loss: 1.3155 - val_accuracy: 0.4314 - val_loss: 1.3512\n",
            "Epoch 5/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - accuracy: 0.4912 - loss: 1.2641 - val_accuracy: 0.4652 - val_loss: 1.2931\n",
            "Epoch 6/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3s/step - accuracy: 0.5385 - loss: 1.1688 - val_accuracy: 0.4751 - val_loss: 1.2346\n",
            "Epoch 7/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3s/step - accuracy: 0.5764 - loss: 1.0702 - val_accuracy: 0.5030 - val_loss: 1.2020\n",
            "Epoch 8/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - accuracy: 0.6110 - loss: 1.0211 - val_accuracy: 0.5487 - val_loss: 1.1592\n",
            "Epoch 9/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - accuracy: 0.6195 - loss: 0.9621 - val_accuracy: 0.5288 - val_loss: 1.1125\n",
            "Epoch 10/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - accuracy: 0.6577 - loss: 0.9016 - val_accuracy: 0.5666 - val_loss: 1.1107\n",
            "Epoch 11/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 3s/step - accuracy: 0.6727 - loss: 0.8939 - val_accuracy: 0.5626 - val_loss: 1.1105\n",
            "Epoch 12/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - accuracy: 0.6742 - loss: 0.8702 - val_accuracy: 0.5785 - val_loss: 1.0550\n",
            "Epoch 13/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3s/step - accuracy: 0.6785 - loss: 0.8590 - val_accuracy: 0.5785 - val_loss: 1.0461\n",
            "Epoch 14/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3s/step - accuracy: 0.7042 - loss: 0.7755 - val_accuracy: 0.5805 - val_loss: 1.0495\n",
            "Epoch 15/15\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - accuracy: 0.7113 - loss: 0.7704 - val_accuracy: 0.6024 - val_loss: 1.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Sugarcane disease model saved at: /content/drive/MyDrive/savedModels/sugarcane_disease_model.h5\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# STEP 2: Set paths for sugarcane\n",
        "dataset_path = '/content/drive/MyDrive/PlantDisease/sugarcane'  # Update for sugarcane dataset\n",
        "model_save_path = '/content/drive/MyDrive/savedModels/sugarcane_disease_model.h5'\n",
        "\n",
        "# STEP 3: Import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# STEP 4: Prepare data generators\n",
        "img_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# STEP 5: Load MobileNetV2 base\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
        "base_model.trainable = False  # Freeze base\n",
        "\n",
        "# STEP 6: Add custom classification head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# STEP 7: Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# STEP 8: Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# STEP 9: Save trained model\n",
        "model.save(model_save_path)\n",
        "print(\"âœ… Sugarcane disease model saved at:\", model_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# STEP 2: Upload a custom image for prediction\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import os\n",
        "image_path = list(uploaded.keys())[0]  # Name of the uploaded image\n",
        "\n",
        "# STEP 3: Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# STEP 4: Load the trained sugarcane model\n",
        "model = load_model('/content/drive/MyDrive/savedModels/sugarcane_disease_model.h5')  # âœ… Adjust path if needed\n",
        "\n",
        "# STEP 5: Preprocess the uploaded image\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# STEP 6: Predict the disease class\n",
        "pred = model.predict(img_array)\n",
        "class_index = np.argmax(pred[0])\n",
        "confidence = np.max(pred[0]) * 100\n",
        "\n",
        "# STEP 7: Class labels and fertilizer suggestions (based on your folder structure)\n",
        "class_labels = ['Healthy', 'Mosaic', 'RedRot', 'Rust', 'Yellow']  # âœ… Matches the folder names in your dataset\n",
        "\n",
        "fertilizer_suggestions = {\n",
        "    'Healthy': 'âœ… No disease detected. Maintain regular fertilization with NPK 18-18-18.',\n",
        "    'Mosaic': 'ğŸ¦  Control aphid vectors using insecticides. Use virus-free planting materials.',\n",
        "    'RedRot': 'ğŸ›¡ Apply fungicides like Carbendazim. Remove infected stalks and practice crop rotation.',\n",
        "    'Rust': 'ğŸŒ« Use fungicides like Mancozeb. Ensure good air circulation and proper drainage.',\n",
        "    'Yellow': 'ğŸŒ¿ Apply micronutrients especially sulfur and zinc. Check for nutrient deficiency and pests.'\n",
        "}\n",
        "\n",
        "# STEP 8: Output the prediction and fertilizer suggestion\n",
        "predicted_label = class_labels[class_index]\n",
        "suggestion = fertilizer_suggestions.get(predicted_label, \"No specific suggestion available.\")\n",
        "\n",
        "print(f\"ğŸ¬ Predicted Disease: {predicted_label}\")\n",
        "print(f\"âœ… Confidence: {confidence:.2f}%\")\n",
        "print(f\"ğŸ’¡ Fertilizer Suggestion: {suggestion}\")\n",
        "\n",
        "# STEP 9: Display the uploaded image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f\"{predicted_label} ({confidence:.2f}%)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4LNOKa7i6lb8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}